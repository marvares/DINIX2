---
title: "Informe Estandarización Perú Escala INDI, Parte 6: Análisis de Conglomerados"
subtitle: "Muestra Nivel 4-5"
author: "Martín Vargas Estrada"
date: "`r Sys.time()`"
output:
  pdf_document:
    toc: true
    toc_depth: 4
  word_document:
    toc: true
    toc_depth: '4'
  html_document:
    toc: true
    toc_depth: '4'
    df_print: paged
header-includes: \renewcommand{\contentsname}{Índice} \renewcommand{\tablename}{Tabla} \renewcommand{\figurename}{Figura}
---
\newpage

# Introducción


En este caso, procederemos a realizar un análisis de conglomerados de los datos, también llamado Cluster Analysis. 

# Marco Conceptual

## Finalidad 

Antes de pasar a los resultados de los análisis en sí, es necesario tener claro en qué consiste el Análisis de Conglomerados.

En general, hasta el momento nos hemos centrado en las variables (de modo principal en las Escalas del INDI, es decir, en sus respectivos puntajes), así como en las relaciones que hemos podido descubrir entre ellas. En esta última sección del Informe, vamos a enfocarnos más bien en los participantes, e intentaremos descubrir si es posible establecer agrupaciones entre tales participantes basándonos en las características cuya información hemos recolectado durante el proceso de evaluación.

Por poner un ejemplo, mediante el análisis de conglomerados podríamos llegar a establecer la existencia de un grupo de participantes que tienen en común su origen (por ejemplo, Lima), el nivel educativo materno (por ejemplo, Postgraduado), un mayor puntaje en la Escala C del INDI, etc., mientras que un segundo conglomerado podría estar formado por participantes cuyo origen es Cusco, tienen madres de nivel educativo Secundario completo, y un puntaje alto en la escala Socioemocional del INDI.

## Estrategias

Para llegar a cumplir nuestra meta de establecer agrupamientos de participantes afines tenemos varias estrategias. No entraremos en el detalle técnico aquí, bastará mencionar que se ha escogido un método o modalidad de Análisis que nos permite incluir tanto variables numéricas (como Edad y los ya mencionados puntajes del INDI) como variables categóricas. Para determinar exactamente cuáles de estas últimas, hemos decidido usar como criterio los resultados del análisis de regresión. Ello nos permite estar seguros de que las variables consideradas tienen de antemano un impacto demostrado en las escalas INDI, evitando modelos con demasiados elementos, lo cual probablemente generaría modelos inútilmente complejos que no añadirían poder explicativo. 

## Parámetros de Análisis

La metodología elegida requiere que definamos de antemano la cantidad de conglomerados para generar nuestro modelo, dándonos la posibilidad de generar múltiple soluciones. 

Por lo tanto, vamos a requerir algún criterio para establecer, si bien no necesariamente una solución "correcta" —ya que en estos casos no podemos establecer ese tipo de certidumbre, por la índole misma del análisis—, sí una solución más eficiente que las otras, tomando como criterio de "eficiencia" el mayor poder explicativo posible con el mínimo número posible de variables. En otras palabras, trataremos de encontrar el modelo más parsimonioso, que nos permita obtener los conglomerados más interpretables, a fin de no complejizar inútilmente el modelo, como ya se mencionó líneas arriba.

Para nuestro caso, ese parámetro de evaluación será el llamado "Coeficiente de Silueta". El coeficiente de silueta es una medida utilizada en análisis de conglomerado para evaluar la calidad de la agrupación de los datos. Se basa en la comparación de la cohesión dentro de un conglomerado con la separación respecto a los otros conglomerados.

- Un clustering o conjunto de conglomerados con un coeficiente de silueta promedio alto (cercano a 1) indica que los clusters están bien definidos.

- Valores cercanos a 0 sugieren clusters solapados.

- Valores negativos indican una mala asignación de puntos a clusters.

En este documento, para mayor legibilidad, hemos incluido solamente la solución que combina los coeficientes de silueta más altos, manteniendo a la vez la simplicidad necesaria para interpretar los clusters resultantes. Consideramos que una solución con muchos clusters, aun si se obtienen coeficientes ligeramente superiores, resultará mucho más difícil de interpretar, y por lo tanto menos útil, que soluciones con coeficiente solo ligeramente inferior pero de un número más manejable de clusters.

Asimismo, los resultados incluyen un gráfico que muestra la proporción de casos que "rebasan" respectivamente el cluster encontrado, así como otro que muestra la representación espacial de los clusters. 
Con esta información en mente, podemos pasar a revisar los resultados obtenidos.



```{r 45_P6_DATA, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}

library(tidyverse)
library(haven)
rm(list = ls()) 
# Carga el archivo .sav
INDI45 <- read_sav("INDI45.sav")
library(tidyverse)

invertir_y_sumar <- function(df, indices_inversos, nombre_variable_sumatoria, posicion_variable) {
  
  # 1. Convertir columnas 75:88 a numéricas
  df <- df %>%
    mutate(across(all_of(names(df)[75:88]), as.numeric))
  
  # 2. Invertir los ítems indicados
  df <- df %>%
    mutate(across(all_of(names(df)[indices_inversos]), ~ 7 - .x))
  
  # 3. Crear la variable sumatoria
  df <- df %>%
    mutate(!!nombre_variable_sumatoria := rowSums(across(all_of(names(df)[75:88]))))
  
  # 4. Reubicar la variable sumatoria en la posición deseada
  col_order <- names(df)  # Obtener nombres de columnas
  
  if (posicion_variable <= length(col_order)) {
    nueva_posicion <- append(col_order, nombre_variable_sumatoria, after = posicion_variable - 1)
    df <- df %>% select(all_of(nueva_posicion))
  }
  
  return(df)
}

# Ejemplo
# Aplicar la función con los valores indicados
INDI45_i <- invertir_y_sumar(
  df = INDI45,
  indices_inversos = c(77:80, 84:88),  # Ítems inversos
  nombre_variable_sumatoria = "SSUM",  # Nombre de la variable sumatoria
  posicion_variable = 104  # Ubicación deseada
)

```



```{r 45_5_Dataframing, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}

ayudin <- function(dataframe, columnas) {
  # Verificar que las columnas seleccionadas sean numéricas
  if (!all(sapply(columnas, function(col) is.numeric(dataframe[[col]])))) {
    stop("Todas las columnas seleccionadas deben ser numéricas.")
  }
  
  # Filtrar el dataframe eliminando filas con NA en las columnas seleccionadas
  dataframe_limpio <- dataframe[complete.cases(dataframe[, columnas]), columnas]
  
  # Devolver el dataframe limpio
  return(dataframe_limpio)
}

# Llamar a la función y mostrar los resultados
LIMPIO <- ayudin(dataframe = INDI45_i, columnas = c(1, 102:105))
# DF Categorial
# Función para convertir variables a factor
convert_to_factor <- function(df, indices) {
  df[indices] <- lapply(df[indices], as.factor)
  return(df)
}
# Convierto a factor

INDI45_Factor<- convert_to_factor(INDI45, c(7,9,11,13,19))
# Me quedo solo con las variables factor que han demostrado tener relación estadísticamente significativa 
library(dplyr)
INDI45_Factor <- INDI45_Factor %>% 
  dplyr::select(Codigo, EDADMES, Regnat, Nivmod, Reg, Quintil, Grainsmad)
# Fusiono con el df numérico sin NA's
PULCRO <- left_join(LIMPIO, INDI45_Factor,  by = "Codigo") # Este df solo tiene casos sin NA's y con las variables factor

# recodificando Niveles
PULCRO$Regnat<- fct_recode(PULCRO$Regnat,
                        "Costa" = "1",
                        "Sierra" = "2",
                        "Selva" = "3")
PULCRO$Nivmod <- fct_recode(PULCRO$Nivmod,
                        "Jardín" = "Inicial - Jardín",
                        "No_Esc" = "Inicial - Programa no escolarizado",
                        "Cuna-Jardín" = "Inicial - Cuna-jardín"
                        )
PULCRO$Reg <- fct_recode(PULCRO$Reg,
                        "Lima Met." = "Lima Metropolitana",
                        "Piura" = "Piura",
                        "Cusco" = "Cusco",
                        "Loreto" = "Loreto"
                        )
colnames(PULCRO) <- c("Código", "Escala_Cog.", "Escala_Mot.", "Escala_Soc", "Escala_Dis.","Edad_Mes", "Región", "Modalidad", "Departamento", "Quintil", "Inst_Mat.")
PULCRO$Inst_Mat. <- fct_relevel(PULCRO$Inst_Mat., "Ninguno", "Inicial", "Primaria incompleto", "Primaria completo", "Secundaria incompleto", "Secundaria completo","Superior técnico incompleto", "Superior técnico completo","Superior universitario incompleto","Superior universitario completo","Posgrado (maestría, doctorado)")
PULCRO$Inst_Mat_N <- fct_recode(PULCRO$Inst_Mat.,
                        "1" = "Ninguno",
                        "2" = "Inicial",
                        "3" = "Primaria incompleto",
                        "4" = "Primaria completo",
                        "5" = "Secundaria incompleto",
                        "6" = "Secundaria completo",
                        "7" = "Superior técnico incompleto",
                        "8" = "Superior técnico completo",
                        "9" = "Superior universitario incompleto",
                        "10" = "Superior universitario completo",
                        "11" = "Posgrado (maestría, doctorado)"
                        )
PULCRO$Inst_Mat_N <- as.numeric(PULCRO$Inst_Mat_N)
PULCRO$Quintil_N <- as.numeric(PULCRO$Quintil)
library(dplyr)

PULCRO <- PULCRO %>% 
  filter(Modalidad != "No_Esc") %>% 
  select(-c(Código, Inst_Mat_N, Quintil_N))
```


\newpage

# Análisis de Conglomerados 

A continuación, pasaremos a realizar el análisis de conglomerados, usando las variables siguientes:

1. Escala Cognitiva
1. Escala Motora
1. Escala Socioemocional
1. Escala Disposicional
1. Edad en Meses
1. Región
1. Modalidad
1. Departamento
1. Quintil
1. Inst. Materna



```{r 45_P6_CLUSTERING, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}
# library(cluster)  
# library(factoextra)
# # Calcular la matriz de distancia de Gower
# dist_matrix <- daisy(PULCRO, metric = "gower")
# kmed <- pam(dist_matrix, k = 6)
# library(factoextra)
# 
# # Convertir las variables categóricas a números antes de graficar
# PULCRO_numeric <- PULCRO %>%
#   mutate(across(where(is.factor), as.numeric))
# 
# # Visualizar los clusters
# fviz_cluster(list(data = PULCRO_numeric, cluster = kmed$clustering))
# 
# print(kmed)  # Resumen del modelo
# summary(kmed)  # Estadísticas del clustering
# table(kmed$clustering)  # Número de casos en cada cluster
# PULCRO$Cluster <- kmed$clustering # Asigno la identificación de a qué cluster pertenece cada caso dentro del dataframe 
# # Resumen de cómo son los casos en cuanto a lo numérico
# PULCRO %>%
#   group_by(Cluster) %>%
#   summarise(across(where(is.numeric), mean, na.rm = TRUE))
# # Resumen de cómo son los casos en cuanto a lo categórico
# PULCRO %>%
#   group_by(Cluster) %>%
#   summarise(across(where(is.factor), ~ names(which.max(table(.x)))))
# # Para ver qué tan bien están agrupadas las observaciones 
# silhouette_score <- silhouette(kmed$clustering, dist_matrix)
# fviz_silhouette(silhouette_score)
# 
# # Calcular la silueta
# silhouette_score <- silhouette(kmed$clustering, dist_matrix)
# 
# # Mostrar el coeficiente promedio de silueta
# cat("Coeficiente de Silueta Promedio:", mean(silhouette_score[, 3]), "\n")
# 
# # Graficar la silueta
# fviz_silhouette(silhouette_score)


```

He aquí los resultados y su interpretación.

## Resultados

```{r 45_P6_CLUSTER_Func, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results='asis'}

# Cargar las librerías necesarias
library(cluster)       # Para el algoritmo PAM
library(factoextra)    # Para visualización y evaluación
library(dplyr)         # Para manipulación de datos
library(knitr)         # Para generar tablas en formato Markdown

# Función para realizar K-Medoids y generar los resultados
kmedoids_analysis <- function(df, num_clusters) {
  
  # 1. Aplicar el algoritmo PAM
  pam_result <- pam(df, k = num_clusters)
  
  # 2. Calcular el coeficiente de silueta
  silhouette_score <- silhouette(pam_result)
  
  # 3. Calcular el coeficiente de silueta promedio
  avg_sil_width <- mean(silhouette_score[, "sil_width"])
  
  # Imprimir el coeficiente de silueta promedio con tres decimales y el número de clústeres
  cat("Coeficiente de Silueta Promedio:", round(avg_sil_width, 3), "\n")
  cat("Número de Conglomerados:", num_clusters, "\n\n")
  
  # 4. Resumen de coeficientes de silueta por clúster
  fviz_sil <- fviz_silhouette(silhouette_score, print.summary = FALSE) # Suprimir la impresión
  silhouette_data <- fviz_sil$data
  silhouette_summary <- silhouette_data %>%
    group_by(cluster) %>%
    summarise(
      n = n(),
      mean_sil_width = round(mean(sil_width, na.rm = TRUE), 2)  # Redondear a dos dígitos
    )
  
  cat("Tabla de Coeficientes de Silueta por Clúster:\n")
  print(knitr::kable(silhouette_summary, format = "markdown"))
  cat("\n")
  
  # 5. Resumen de las características numéricas de cada clúster
  cat("Resumen de Variables Numéricas por Clúster:\n")
  
  # Añadir la asignación de clústeres al dataframe original
  df$Cluster <- pam_result$clustering
  
  # numeric_summary <- df %>%
  #   group_by(Cluster) %>%
  #   summarise(across(where(is.numeric), mean, na.rm = TRUE))
  numeric_summary <- df %>%
  group_by(Cluster) %>%
  summarise(across(where(is.numeric), ~ round(mean(.x, na.rm = TRUE), 2)))
  
  print(knitr::kable(numeric_summary, format = "markdown"))
  cat("\n")
  
  # 6. Resumen de las características categóricas de cada clúster
  cat("Resumen de Variables Categóricas por Clúster:\n")
  
  categorical_summary <- df %>%
    group_by(Cluster) %>%
    summarise(across(where(is.factor), ~ names(which.max(table(.x)))[1]))
  
  print(knitr::kable(categorical_summary, format = "markdown"))
  cat("\n")
  
  # 7. Gráfico de silueta con título en castellano
  # cat("Gráfico de Silueta:\n")
  plot(fviz_sil)
  
  # Gráfico del clustering (Cluster Plot)
  # cat("Gráfico de Clústeres:\n")
  cluster_plot <- fviz_cluster(pam_result, data = df[, -ncol(df)], geom = "point") +
    ggtitle("Gráfico de Clústeres") +
    theme_gray()
  
  print(cluster_plot)
  
  # Eliminar la columna "Cluster" del dataframe (opcional)
  df$Cluster <- NULL
  
  # Devolver los resultados
  return(list(
    silhouette_avg = avg_sil_width,
    silhouette_table = silhouette_summary,
    numeric_summary = numeric_summary,
    categorical_summary = categorical_summary,
    silhouette_plot = fviz_sil,
    cluster_plot = cluster_plot
  ))
}



# Puedes ejecutar la función así:
results <- kmedoids_analysis(PULCRO, 2)

# Para acceder a los resultados individuales:
# results$silhouette_avg
# results$silhouette_table
# results$numeric_summary
# results$categorical_summary
# results$silhouette_plot




```

## Interpretación 


### Análisis General

El algoritmo ha creado dos clusters a partir de los datos

El Cluster 1 es más numeroso que el Cluster 2, por poco menos de 500 casos (448, para ser exactos).

El Coeficiente de Silueta Promedio es 0.468
  - Cluster 1: 0.48
  - Cluster 2: 0.44

Generalmente, valores entre 0.25 y 0.50 indican una estructura de cluster moderadamente fuerte.

Sin embargo, el coeficiente de silueta no es muy alto, lo cual indica cierto solapamiento entre clusters, es decir los grupos no están perfectamente separados, como apreciamos en el Gráfico correspondiente.

### Análisis de Variables Numéricas

Este análisis nos dice cómo se diferencian los dos grupos en las variables numéricas. 

- El Cluster 2 tiene puntajes significativamente más altos en todas las escalas cognitivas, motivacionales y sociales.

- El Cluster 1 tiene puntajes más bajos en todas las variables, lo que implica que los individuos de este grupo pueden tener menor desempeño en la prueba.

- Edad en meses:  
  - Cluster 1: 60.83 meses (~5 años y 1 mes)  
  - Cluster 2: 64.80 meses (~5 años y 5 meses)  
  - Diferencia: Cluster 2 es, en promedio, 4 meses mayor que Cluster 1.  
  - Esto podría indicar, como ya hemos visto en niveles previos de análisis, que la edad influye en el desempeño de la prueba.
  
### Análisis de Variables Categóricas

Este análisis nos ayuda a ver dónde viven estos participantes, su nivel socioeconómico y el nivel educativo de sus madres. 

Los participantes de ambos clusters están más frecuentemente ubicados en la Costa y en la modalidad "Jardín" (educación inicial).

En el Cluster 1 hay mayoría de niños de Piura, mientras que el Cluster 2 tiene mayoría de Lima Metropolitana.

El nivel socioeconómico más frecuente similar (Quintil 4) en ambos clusters.

El nivel educativo materno más frecuente en ambos grupos es "Secundaria completa", lo que sugiere que esta variable no parece ser un factor diferenciador en el clustering.

## Conclusiones Generales

1. Diferencia en desempeño del INDI:  
   - El Cluster 2 tiene un desempeño superior en todas las escalas.
   - Esto puede estar relacionado con factores como edad, ubicación geográfica o factores no medidos asociados (calidad educativa, acceso a recursos, etc.).

2. Ubicación geográfica:  
   - Piura (Cluster 1) vs. Lima Metropolitana (Cluster 2).
   - Esto sugiere que los niños de Lima pueden estar obteniendo mejores resultados en la prueba.
   - Puede haber diferencias en la calidad educativa o en el acceso a oportunidades de aprendizaje.

3. Edad como factor de influencia:  
   - El Cluster 2 es un poco mayor (4 meses mayor, en promedio).
   - Aunque parece una diferencia pequeña, a esta edad (5 años), meses adicionales pueden representar una ventaja en términos de maduración, desarrollo cognitivo y habilidades sociales.